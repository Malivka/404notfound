{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f6b2b8",
   "metadata": {},
   "source": [
    "Here‚Äôs a **clean, concept-first explanation** of what you‚Äôve written, without drowning you in output details.\n",
    "\n",
    "---\n",
    "\n",
    "## B.3 Model Training ‚Äî Core Ideas\n",
    "\n",
    "### 1Ô∏è‚É£ Holdout Method (Train‚ÄìTest Split)\n",
    "\n",
    "**What it is**\n",
    "\n",
    "* You split the dataset **once** into:\n",
    "\n",
    "  * **Training set** ‚Üí used to build the model\n",
    "  * **Test set** ‚Üí used to evaluate the model on unseen data\n",
    "\n",
    "**Why it‚Äôs needed**\n",
    "\n",
    "* To check whether the model **generalizes** beyond the data it learned from.\n",
    "\n",
    "**How scikit-learn does it**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test = train_test_split(\n",
    "    data,\n",
    "    test_size=0.3,\n",
    "    random_state=123\n",
    ")\n",
    "```\n",
    "\n",
    "**Key points**\n",
    "\n",
    "* `test_size=0.3` ‚Üí 30% test, 70% train\n",
    "* `random_state` ‚Üí ensures **reproducibility**\n",
    "* Without `random_state`, every run gives a **different split**\n",
    "\n",
    "**Limitation**\n",
    "\n",
    "* Model performance depends heavily on **one random split**\n",
    "* Risky for small datasets\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ K-Fold Cross-Validation\n",
    "\n",
    "**What it is**\n",
    "\n",
    "* Data is split into **k equal parts (folds)**\n",
    "* Each fold is used **once as test**, remaining folds as train\n",
    "* Final performance = **average over k runs**\n",
    "\n",
    "For `k = 10`:\n",
    "\n",
    "* Train 10 models\n",
    "* Each data point is tested **exactly once**\n",
    "\n",
    "---\n",
    "\n",
    "### How KFold Works in scikit-learn\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=123)\n",
    "```\n",
    "\n",
    "**Important details**\n",
    "\n",
    "* `shuffle=True` ‚Üí avoids biased folds\n",
    "* `random_state` ‚Üí same folds every run\n",
    "* `kf.split(data)` **does not split data**\n",
    "\n",
    "  * It returns **indices**\n",
    "\n",
    "---\n",
    "\n",
    "### Understanding `kf.split(data)`\n",
    "\n",
    "```python\n",
    "for train_index, test_index in kf.split(data):\n",
    "    data_train = data.iloc[train_index]\n",
    "    data_test  = data.iloc[test_index]\n",
    "```\n",
    "\n",
    "**What you get**\n",
    "\n",
    "* `train_index` ‚Üí row numbers for training\n",
    "* `test_index` ‚Üí row numbers for testing\n",
    "\n",
    "This is why you see **huge index lists** in the output.\n",
    "\n",
    "---\n",
    "\n",
    "### Accessing a Specific Fold\n",
    "\n",
    "```python\n",
    "folds = []\n",
    "for train_index, test_index in kf.split(data):\n",
    "    folds.append((train_index, test_index))\n",
    "\n",
    "train_index, test_index = folds[3]  # 4th fold\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Holdout vs K-Fold (Quick Comparison)\n",
    "\n",
    "| Aspect           | Holdout | K-Fold |\n",
    "| ---------------- | ------- | ------ |\n",
    "| Number of splits | 1       | k      |\n",
    "| Stability        | Low     | High   |\n",
    "| Bias             | Higher  | Lower  |\n",
    "| Computation      | Fast    | Slower |\n",
    "| Small datasets   | ‚ùå       | ‚úÖ      |\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use What?\n",
    "\n",
    "* **Large dataset, quick experiment** ‚Üí Holdout\n",
    "* **Small/medium dataset, reliable evaluation** ‚Üí K-Fold\n",
    "* **Research / reproducibility** ‚Üí K-Fold + fixed `random_state`\n",
    "\n",
    "---\n",
    "\n",
    "### Mental Model (Easy to Remember)\n",
    "\n",
    "* **Holdout** = one exam\n",
    "* **K-Fold** = average of multiple exams\n",
    "\n",
    "You‚Äôre building solid foundations here‚Äîthis is exactly how real ML pipelines are evaluated. Keep going üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba3241",
   "metadata": {},
   "source": [
    "Excellent ‚Äî this is a **classic lab handout**, and your request is clear üëç\n",
    "Below is **ALL code extracted and separated into clean, independent Jupyter cells**, exactly how an assignment notebook should look.\n",
    "\n",
    "You can **copy‚Äìpaste cell by cell**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 1 ‚Äì Import Pandas\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 2 ‚Äì Feature Construction: Derived Feature (Area)\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    'length': [20, 25, 30, 22],\n",
    "    'breadth': [15, 20, 18, 25],\n",
    "    'price': [200000, 250000, 300000, 220000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['area'] = df['length'] * df['breadth']\n",
    "df\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 3 ‚Äì Encoding Nominal Variables (One-Hot Encoding)\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    'city': ['A', 'B', 'C', 'A'],\n",
    "    'parents_athlete': ['Y', 'N', 'N', 'Y'],\n",
    "    'chance_of_win': ['Y', 'N', 'Y', 'N']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "pd.get_dummies(df, drop_first=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 4 ‚Äì Encoding Ordinal Variables\n",
    "\n",
    "```python\n",
    "data = {'grade': ['A', 'B', 'C', 'D', 'A']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "grade_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n",
    "df['num_grade'] = df['grade'].map(grade_map)\n",
    "df\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 5 ‚Äì Binning Continuous Variables\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'price': [200000, 350000, 600000, 800000]})\n",
    "\n",
    "bins = [0, 300000, 600000, np.inf]\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "df['price_category'] = pd.cut(df['price'], bins=bins, labels=labels)\n",
    "df\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 6 ‚Äì PCA (Feature Extraction)\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(\"Original shape:\", X.shape)\n",
    "print(\"Reduced shape:\", X_pca.shape)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 7 ‚Äì Truncated SVD\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "X = np.random.rand(5, 4)\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "X_svd = svd.fit_transform(X)\n",
    "\n",
    "print(\"Original:\", X.shape)\n",
    "print(\"Reduced:\", X_svd.shape)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 8 ‚Äì LDA (Linear Discriminant Analysis)\n",
    "\n",
    "```python\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "print(\"Original shape:\", X.shape)\n",
    "print(\"Reduced shape:\", X_lda.shape)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 9 ‚Äì Feature Selection: Chi-Square (Filter Method)\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(iris.data, iris.target)\n",
    "\n",
    "print(\"Original:\", iris.data.shape)\n",
    "print(\"Reduced:\", X_new.shape)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 10 ‚Äì Chi-Square using `.iloc`\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X = df.iloc[:, :-1]   # all columns except last\n",
    "y = df.iloc[:, -1]    # last column\n",
    "\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "\n",
    "print(\"Original shape:\", X.shape)\n",
    "print(\"Reduced shape:\", X_new.shape)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 11 ‚Äì Wrapper Method: Recursive Feature Elimination (RFE)\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "print(\"Selected Features:\", fit.support_)\n",
    "print(\"Feature Ranking:\", fit.ranking_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cell 12 ‚Äì Embedded Method: Lasso (LassoCV)\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "df_d = diabetes.frame\n",
    "\n",
    "X = df_d.iloc[:, :-1]\n",
    "y = df_d.iloc[:, -1]\n",
    "\n",
    "lasso = LassoCV(cv=5)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "print(\"Coefficients:\", lasso.coef_)\n",
    "print(\"Number of selected features:\", sum(lasso.coef_ != 0))\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55dba5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load example dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "target = pd.Series(iris.target)\n",
    "\n",
    "print(data.head())\n",
    "print(target.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02088eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.3, random_state=123\n",
    ")\n",
    "\n",
    "# Train a simple model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Holdout Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad15b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 1.0000\n",
      "Fold 2 Accuracy: 0.9667\n",
      "Fold 3 Accuracy: 0.9667\n",
      "Fold 4 Accuracy: 0.9667\n",
      "Fold 5 Accuracy: 0.9333\n",
      "Average K-Fold Accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# K-Fold setup: 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    fold_accuracies.append(acc)\n",
    "    \n",
    "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(f\"Average K-Fold Accuracy: {np.mean(fold_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c345ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (120, 4)\n",
      "Test shape: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "# Save folds into a list\n",
    "folds = list(kf.split(data))\n",
    "\n",
    "# Get 3rd fold indices (remember Python indexing starts at 0)\n",
    "train_index, test_index = folds[2]\n",
    "\n",
    "X_train_fold3 = data.iloc[train_index]\n",
    "X_test_fold3 = data.iloc[test_index]\n",
    "y_train_fold3 = target.iloc[train_index]\n",
    "y_test_fold3 = target.iloc[test_index]\n",
    "\n",
    "print(\"Train shape:\", X_train_fold3.shape)\n",
    "print(\"Test shape:\", X_test_fold3.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
